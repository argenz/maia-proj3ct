[
  {
    "id": "test_email_1",
    "subject": "Latest AI Research Breakthroughs - December 2025",
    "from": "AI Weekly <newsletter@aiweekly.co>",
    "date": "Thu, 26 Dec 2025 08:00:00 -0500",
    "body_html": "<html><body><h1>This Week in AI</h1><p>Researchers at MIT have developed a new transformer architecture that achieves state-of-the-art performance on language understanding tasks. The model uses a novel attention mechanism that reduces computational complexity by 40%.</p><p><a href=\"https://example.com/paper1\">Read the full paper</a></p><h2>New Tools</h2><p>OpenAI released a new code generation tool that can automatically write unit tests for your codebase. Early users report 90% accuracy in test generation.</p><p><a href=\"https://example.com/tool1\">Try the beta</a></p></body></html>",
    "body_text": "This Week in AI\n\nResearchers at MIT have developed a new transformer architecture that achieves state-of-the-art performance on language understanding tasks. The model uses a novel attention mechanism that reduces computational complexity by 40%.\n\nRead the full paper: https://example.com/paper1\n\nNew Tools\n\nOpenAI released a new code generation tool that can automatically write unit tests for your codebase. Early users report 90% accuracy in test generation.\n\nTry the beta: https://example.com/tool1"
  },
  {
    "id": "test_email_2",
    "subject": "The Rundown: AI Industry Updates",
    "from": "The Rundown <digest@therundown.ai>",
    "date": "Thu, 26 Dec 2025 09:00:00 -0500",
    "body_html": "<html><body><h1>Industry News</h1><p>Google announced a major investment in AI safety research, committing $500M over the next three years. The initiative will focus on alignment research and interpretability.</p><p><a href=\"https://example.com/news1\">Full announcement</a></p><p>Anthropic's Claude 4 is now available with extended context windows up to 500K tokens, enabling analysis of entire codebases and long documents.</p></body></html>",
    "body_text": "Industry News\n\nGoogle announced a major investment in AI safety research, committing $500M over the next three years. The initiative will focus on alignment research and interpretability.\n\nFull announcement: https://example.com/news1\n\nAnthropic's Claude 4 is now available with extended context windows up to 500K tokens, enabling analysis of entire codebases and long documents."
  },
  {
    "id": "test_email_3",
    "subject": "AI Research Digest - Latest Papers",
    "from": "Research Digest <papers@substack.com>",
    "date": "Thu, 26 Dec 2025 10:00:00 -0500",
    "body_html": "<html><body><h1>Top Papers This Week</h1><p><strong>Scaling Laws for Neural Language Models</strong> - Stanford researchers identify new scaling laws that predict model performance more accurately across different architectures and training regimes.</p><p><a href=\"https://example.com/paper2\">arXiv preprint</a></p><p><strong>Efficient Fine-Tuning with LoRA</strong> - A new parameter-efficient fine-tuning method that achieves competitive results with 100x fewer parameters.</p></body></html>",
    "body_text": "Top Papers This Week\n\nScaling Laws for Neural Language Models - Stanford researchers identify new scaling laws that predict model performance more accurately across different architectures and training regimes.\n\narXiv preprint: https://example.com/paper2\n\nEfficient Fine-Tuning with LoRA - A new parameter-efficient fine-tuning method that achieves competitive results with 100x fewer parameters."
  }
]
